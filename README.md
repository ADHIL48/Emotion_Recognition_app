
 <img src="https://github.com/ADHIL48/Emotion_Recognition_app/raw/main/Emotion_Recognition%20_App_Using_Streamlit/images/logo.png" alt="Big Smile Emoji" width="150px" align="right"><h1 align="center">ðŸŽ­ Feel My Emotion - Multi-Modal Emotion Recognition App</h1>


> An intelligent, multi-modal emotion recognition system that understands how you feelâ€”through your words, face, and voice.

<div style="display: flex; justify-content: space-around; flex-wrap: wrap;">
  <img src="https://github.com/ADHIL48/Emotion_Recognition_app/raw/main/Emotion_Recognition%20_App_Using_Streamlit/images/Emoji/Happy.gif" alt="Happy" width="90"/>
  <img src="https://github.com/ADHIL48/Emotion_Recognition_app/raw/main/Emotion_Recognition%20_App_Using_Streamlit/images/Emoji/gif/angry.gif" alt="Angry" width="90"/>
  <img src="https://github.com/ADHIL48/Emotion_Recognition_app/raw/main/Emotion_Recognition%20_App_Using_Streamlit/images/Emoji/Neutral.gif" alt="Neutral" width="90"/>
  <img src="https://github.com/ADHIL48/Emotion_Recognition_app/raw/main/Emotion_Recognition%20_App_Using_Streamlit/images/Emoji/Sad.gif" alt="Sad" width="90"/>
  <img src="https://github.com/ADHIL48/Emotion_Recognition_app/raw/main/Emotion_Recognition%20_App_Using_Streamlit/images/Emoji/gif/disgust.gif" alt="Disgust" width="90"/>
  <img src="https://github.com/ADHIL48/Emotion_Recognition_app/raw/main/Emotion_Recognition%20_App_Using_Streamlit/images/Emoji/Disgust.gif" alt="Fear" width="90"/>
  <img src="https://github.com/ADHIL48/Emotion_Recognition_app/raw/main/Emotion_Recognition%20_App_Using_Streamlit/images/Emoji/gif/surprise.gif" alt="Pleasant Surprise" width="90"/>
  <img src="https://github.com/ADHIL48/Emotion_Recognition_app/raw/main/Emotion_Recognition%20_App_Using_Streamlit/images/Emoji/gif/love.gif" alt="Love" width="90"/>
  <img src="https://github.com/ADHIL48/Emotion_Recognition_app/raw/main/Emotion_Recognition%20_App_Using_Streamlit/images/Emoji/gif/humor.gif" alt="Humor" width="90"/>
</div>

---

## ðŸ“Œ Table of Contents

- [ðŸŒŸ Project Overview](#-project-overview)
- [âœ¨ Key Features](#-key-features)
- [ðŸ›  Technologies Used](#-technologies-used)
- [ðŸ“¥ Installation Guide](#-installation-guide)
- [ðŸš€ Usage Instructions](#-usage-instructions)
- [ðŸ“‚ Project Structure](#-project-structure)
- [ðŸ§  Models Architecture](#-models-architecture)
- [ðŸ“Š Performance Metrics](#-performance-metrics)
- [ðŸ“¡ API Documentation](#-api-documentation)
- [ðŸ“¸ Screenshots](#-screenshots)
- [ðŸš€ Future Enhancements](#-future-enhancements)
- [ðŸ¤ Contributing](#-contributing)
- [ðŸ“œ License](#-license)
- [ðŸ“ž Contact](#-contact)

---

## ðŸŒŸ Project Overview

**Feel My Emotion** is a multi-modal emotion recognition app that uses machine learning to analyze human emotions via text, facial expressions, and speech. Whether you're typing a message, recording your voice, or showing your face on camera, the app can detect and interpret your emotional state in real-time.

âœ… Multi-modal inputs  
âœ… Personalized wellbeing recommendations  
âœ… Visualizations & analytics dashboard  
âœ… Emotional support AI chatbot  

---

## âœ¨ Key Features

### ðŸ”¤ Text Emotion Recognition
- Supports typed input and TXT file uploads
- Detects 8 emotions: ðŸ˜Š Happy, ðŸ˜¢ Sad, ðŸ˜  Angry, ðŸ˜¨ Fearful, ðŸ¤¢ Disgusted, ðŸ˜² Surprised, ðŸ˜ Neutral, â¤ï¸ Loving

### ðŸ“· Face Emotion Recognition
- Static and real-time webcam-based analysis
- Emotion & gender detection
- Multi-face support

### ðŸŽ™ Speech Emotion Recognition
- Record live audio (5s segments) or upload `.wav` files
- MFCC-based analysis with waveform visualization

### ðŸ” Multi-Modal Emotion Analysis
- Combines all modalities with a weighted approach
- Final report includes emotion agreement insights

### ðŸ’¬ Chat & Visual Features
- AI-powered emotion chatbot (LangChain & Ollama)
- Radar and bar charts for emotion breakdown
- Emotion GIF reactions
- Dark/light mode support
- Historical tracking & usage streaks

---

## ðŸ›  Technologies Used

| Tech         | Purpose                      | Version   |
|--------------|------------------------------|-----------|
| Python       | Backend logic                | 3.9+      |
| Streamlit    | Frontend web interface       | 1.22+     |
| DeepFace     | Facial emotion analysis      | 0.0.79    |
| Librosa      | Audio feature extraction     | 0.9.2     |
| Scikit-learn | Text classification (NLP)    | 1.2.2     |
| TensorFlow   | Speech emotion CNN model     | 2.12.0    |
| Plotly, Altair| Interactive visualizations   | 5.14.1, 4.2.2 |
| LangChain    | LLM & AI chatbot integration | 0.0.200   |
| Ollama       | Local language model server  | 0.1.0     |

---

## ðŸ“¥ Installation Guide

### âš™ï¸ System Requirements

- Minimum 4GB RAM, 2GB Disk
- Webcam (Face), Microphone (Speech)

### ðŸ§± Setup Steps

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate        # Linux/macOS
venv\Scripts\activate           # Windows

# Install dependencies
pip install -r requirements.txt

# Optional (Linux dependencies)
sudo apt-get install -y libsndfile1 ffmpeg
```

### ðŸ§  Model Downloads

On first run, models for text, speech, and face analysis are auto-downloaded.

### âš™ï¸ Environment Variables

Create a `.env` file:

```env
DARK_MODE=True
DEFAULT_MODALITY=multi
```

### â–¶ï¸ Run the App

```bash
streamlit run app.py
```

---

## ðŸš€ Usage Instructions

#### ðŸ”¤ Text Analysis
- Enter short text or upload `.txt` file
- View predicted emotion, confidence, and recommendation

#### ðŸ“¸ Face Analysis
- Choose static photo or enable webcam
- Real-time results with emotion, confidence, and gender labels

#### ðŸŽ¤ Speech Analysis
- Record or upload `.wav` audio
- View waveform and emotion probabilities

#### ðŸ” Multi-Modal Flow
- Complete all 3 steps
- Final confidence-weighted emotion result + report

---

## ðŸ“‚ Project Structure

```
Emotion_Recognition_app/
â”œâ”€â”€ main/                   # Application source code
â”‚   â”œâ”€â”€ app.py              # Main Streamlit app
â”‚   â”œâ”€â”€ models/             # ML models for each modality
â”‚   â”œâ”€â”€ utils/              # Helper and visualization functions
â”‚   â”œâ”€â”€ assets/             # Images and emotion GIFs
â”‚   â””â”€â”€ tests/              # Unit & integration tests
â”œâ”€â”€ docs/                   # API and architecture docs
â”œâ”€â”€ requirements.txt        # Dependency list
â”œâ”€â”€ .env.example            # Environment variable template
â”œâ”€â”€ LICENSE                 # MIT License
â””â”€â”€ README.md               # Project README
```

---

## ðŸ§  Models Architecture

### Text Classifier (Logistic Regression)
- TF-IDF with n-gram (1,3)
- Dataset: ISEAR
- Accuracy: 86%

### Speech Classifier (1D CNN)
- Features: MFCC (40 coefficients)
- Dataset: RAVDESS
- Accuracy: 78%

### Face Classifier (VGG-Face)
- Dataset: FER-2013
- Accuracy: 72%
- Outputs: Emotion + Gender

---

## ðŸ“Š Performance Metrics

| Modality | Precision | Recall | F1-Score | Avg Inference |
|----------|-----------|--------|----------|----------------|
| Text     | 0.86      | 0.85   | 0.85     | 120ms          |
| Speech   | 0.78      | 0.76   | 0.77     | 380ms          |
| Face     | 0.72      | 0.71   | 0.71     | 680ms          |
| Multi-modal | â€”      | â€”      | â€”        | 3.2s           |


---

## ðŸš€ Future Enhancements

### Features Coming Soon
- ðŸ“± React Native mobile app
- ðŸ“Š Emotion trend timeline
- ðŸ§˜ Health app sync (Apple/Google)
- ðŸ““ AI mood journal
- ðŸ©º Therapist dashboard (Pro edition)

### Technical Upgrades
- ðŸ’¡ Transformers for NLP
- ðŸ—£ Transfer learning in speech
- ðŸŽ¥ 3D CNN for video-based emotion
- ðŸŒ ONNX edge deployment
- ðŸŒ Multi-language support

---

## ðŸ¤ Contributing

We welcome contributions!

```bash
# Set up environment
git clone https://github.com/ADHIL48/Emotion_Recognition_app.git
cd Emotion_Recognition_app
pip install -r requirements-dev.txt

# Run tests
pytest tests/

# Format code
black .
```

Please read [CONTRIBUTING.md](CONTRIBUTING.md) for details.

---

## ðŸ“œ License

**MIT License**  
See full text in [LICENSE](LICENSE)

---

## ðŸ“ž Contact

**Adhil M**  
ðŸ“§ [mohammedadhil0408@gmail.com](mailto:mohammedadhil0408@gmail.com)  
ðŸŒ [GitHub](https://github.com/ADHIL48) | [LinkedIn](https://linkedin.com/in/adhil-m) | ðŸ“± WhatsApp: +91 6382191903

ðŸ”— **Project Links**:  
- [ðŸ”§ GitHub Repository](https://github.com/ADHIL48/Emotion_Recognition_app)  
- [ðŸ“º Live Demo (Streamlit)](https://share.streamlit.io/adhil48/emotion_recognition_app/main/app.py)

---

> ðŸ’¬ _"Your emotions matter. Let your apps feel them too."_
```
